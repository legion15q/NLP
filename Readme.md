# Решение задачи таргетированного анализа тональностей по отношению к выбранной целевой сущности с помощью нейронных сетей и метода, основанного на словарях оценочной лексики.
## Установка
Для обучения моделей на полученных в работе датасетах необходимо настроить `config.ini` файл:  
### Структура файла `config.ini`:  
- model=`путь к токенизатору модели на huggingface` (доступны `"sberbank-ai/sbert_large_nlu_ru"` и `"cointegrated/rubert-tiny2"`)
- LR=`Learning Rate` ([1e-4,1e-8]) 
- batch_size=`зависит от характеристик видеокарты` (по умолчанию 6)
- epochs=`количество эпох для обучения` (по умолчанию 5)  
- save_top_n=`сохранить n лучших моделей` (по умолчанию 3)
### Запуск обучения моделей  
Запустить скрипт `train_multiclass_bert.py` в папке `multiclass_classification` для обучения модели на основе мультиклассовой классификации (multiclass classification)  Запустить скрипт `train_multilabel_bert.py` в папке `multilabel_classification` для обучения модели на основе неисключающей мультиклассовой классификации (multilabel classification)
### Тестирование моделей на своих данных
Для каждой модели в соответствующей папке есть скрипт user_interface.py
## Модели  
`multilabel_classification` -- обучение нейронной сети на основе BERT для задачи классификации тональности по отношению к выбранной сущности во входном предложении, где тональности кодируются следующим образом:  
* Нейтральная тональность: [1, 0, 0]
* Негативная тональность: [0, 0, 1]
* Позитивная тональность: [0, 1, 0]
* Противоречивая тональность: [0, 1, 1]  
Для балансировки выборки используется процедура upsampling
### Гиперпараметры модели:  
- Оптмизатор: AdamW()
- Функция потерь: MultiMarginSoftLoss()
- Learning Rate = 1e-8
- Разбиение выборок см. в `create_*_dataset.py`
### Метрики полученной модели:  
| class   | precision | recall | f1-score | support | 
|---------|:---------:|---------:|---------:|---------|
neutral    |   0.94   |   0.65    |  0.77    |   773 |
positive    |   0.26    |  0.47    |  0.33     |   77 |
negative    |   0.32 |     0.75    |  0.45   |    104 |
pos-neg    |   0.06   |   0.50  |    0.11    |     6 |
macro avg   |    0.40  |    0.59  |    0.42    |   960 |
weighted avg   |    0.81  |    0.64  |    0.69  |     960 |

| class | accuracy | support |
|---------|:---------:|---------:|
neutral | 0.64  | 773 |
positive | 0.46 | 77 |
negative | 0.75 | 104 |
neg-pos | 0.50 | 6 |
TOTAL | 0.64 | 960 |

`multiclass_classification` -- обучение нейронной сети на основе BERT для задачи классификации тональности по отношению к выбранной сущности во входном предложении, где тональности кодируются следующим образом:  
* Нейтральная тональность: 0  
* Негативная тональность: -1  
* Позитивная тональность: 1  
* Противоречивая тональность: -2  
Для балансировки выборки используется процедура upsampling
### Гиперпараметры модели:
- Оптмизатор: AdamW()
- Функция потерь: MultiMarginLoss()
- Learning Rate = 1e-8
- Разбиение выборок см. в `create_*_dataset.py`
### Метрики полученной модели:  
| class   | precision | recall | f1-score | support | 
|---------|:---------:|---------:|---------:|---------|
neutral    |   0.90  |    0.62   |   0.74   |    773 |
positive    |   0.24   |   0.52  |    0.33      |  77 |
negative   |    0.28   |   0.70   |   0.40    |   104 |
pos-neg    |   0.00  |    0.00  |    0.00     |    6 |
macro avg  |     0.36   |   0.46    |  0.37   |    960 |
weighted avg   |    0.78  |    0.62   |   0.66   |    960|

| class | accuracy | support |
|---------|:---------:|---------:|
neutral | 0.61  | 773|
positive | 0.51 | 77 |
negative | 0.70 | 104 |
neg-pos | 0.00 | 6 |
TOTAL | 0.62 | 960 |

`dict_method` -- гибридный метод, использовалась предобученная модель BERT (https://huggingface.co/sberbank-ai/sbert_large_nlu_ru) для получения эмбеддингов предложений и последующего расчета семантической близости для решения задачи многозначности слов в контексте, а также словарь оценочной лексики RuSentiLex (https://www.labinform.ru/pub/rusentilex/index.htm)
### Метрики полученной модели:  
| class   | precision | recall | f1-score | support | 
|---------|:---------:|---------:|---------:|---------|
neutral    |   0.84    |  0.95 |     0.89    |   773 |
positive    |  0.37   |   0.25   |   0.29      |  77 |
negative   |    0.59   |   0.18   |   0.28    |   104 |
pos-neg    |   0.00   |   0.00  |    0.00    |     6 |
macro avg     |  0.45  |    0.34   |   0.37   |    960|
weighted avg     |  0.77    |  0.80   |   0.77   |    960

| class | accuracy | support |
|---------|:---------:|---------:|
neutral | 0.94  | 773|
positive | 0.24 | 77 |
negative | 0.18 | 104 |
neg-pos | 0.00 | 6 |
TOTAL | 0.80 | 960 |
